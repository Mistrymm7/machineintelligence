{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%config InlineBackend.figure_format = 'retina'\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "import numpy as np\n",
    "np.set_printoptions(precision=3)\n",
    "np.set_printoptions(suppress=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating Mini-batches For Neural Network Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Combining data points with their labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have two numpy arrays `dpoints` and `labels`. Let's imagine that `dpoints` contains our data points, and `labels` the corresponding labels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "dpoints = np.array([1,2,3,4,5,6,7,8,9,10,11,12,13])\n",
    "labels = np.array(['A','B','C','D','E','F','G','H','I','J','K','L','M'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use the `zip` function to combine them and then interate trought the zipped object:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 A\n",
      "2 B\n",
      "3 C\n",
      "4 D\n",
      "5 E\n",
      "6 F\n",
      "7 G\n",
      "8 H\n",
      "9 I\n",
      "10 J\n",
      "11 K\n",
      "12 L\n",
      "13 M\n"
     ]
    }
   ],
   "source": [
    "for dp, l in zip(dpoints, labels):\n",
    "    print (dp, l)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, if we try to print the zip object, we get this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<zip at 0x7fbe41998320>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zip(dpoints, labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we wanted to convert the zip object into a list, we can use the `list` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1, 'A'),\n",
       " (2, 'B'),\n",
       " (3, 'C'),\n",
       " (4, 'D'),\n",
       " (5, 'E'),\n",
       " (6, 'F'),\n",
       " (7, 'G'),\n",
       " (8, 'H'),\n",
       " (9, 'I'),\n",
       " (10, 'J'),\n",
       " (11, 'K'),\n",
       " (12, 'L'),\n",
       " (13, 'M')]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(zip(dpoints, labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we wanted to turn the zip into a numpy array, we can use the command `np.array()` on top of the `list` command:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['1', 'A'],\n",
       "       ['2', 'B'],\n",
       "       ['3', 'C'],\n",
       "       ['4', 'D'],\n",
       "       ['5', 'E'],\n",
       "       ['6', 'F'],\n",
       "       ['7', 'G'],\n",
       "       ['8', 'H'],\n",
       "       ['9', 'I'],\n",
       "       ['10', 'J'],\n",
       "       ['11', 'K'],\n",
       "       ['12', 'L'],\n",
       "       ['13', 'M']], dtype='<U21')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = np.array(list(zip(dpoints, labels)))\n",
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The variable `dataset` now contains both data points and labels."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating mini-batches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Shuffling the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The idea of mini-batches is to take a large data set (like MNIST), and split it into smaller, managable chunks of data that can be trained more efficiently using our algorithm. Let's see how this can be accomplished using `dataset`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['1', 'A'],\n",
       "       ['2', 'B'],\n",
       "       ['3', 'C'],\n",
       "       ['4', 'D'],\n",
       "       ['5', 'E'],\n",
       "       ['6', 'F'],\n",
       "       ['7', 'G'],\n",
       "       ['8', 'H'],\n",
       "       ['9', 'I'],\n",
       "       ['10', 'J'],\n",
       "       ['11', 'K'],\n",
       "       ['12', 'L'],\n",
       "       ['13', 'M']], dtype='<U21')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we define the size of chunks that we would like to subdivide our data into with `mb_size`. Then we compute the length of our data with `data_len`: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chunk size: 3, number of data points 13\n"
     ]
    }
   ],
   "source": [
    "mb_size = 3\n",
    "data_len = len(dataset)\n",
    "print (f'chunk size: {mb_size}, number of data points {data_len}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In every epoch, we should first shuffle our data set as it was a deck of cards. If our dataset is a numpy array, we can shuffle it by using the command `np.random.shuffle`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['9' 'I']\n",
      " ['7' 'G']\n",
      " ['1' 'A']\n",
      " ['5' 'E']\n",
      " ['4' 'D']\n",
      " ['13' 'M']\n",
      " ['6' 'F']\n",
      " ['3' 'C']\n",
      " ['11' 'K']\n",
      " ['12' 'L']\n",
      " ['10' 'J']\n",
      " ['8' 'H']\n",
      " ['2' 'B']]\n"
     ]
    }
   ],
   "source": [
    "np.random.shuffle(dataset)\n",
    "print(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Every time we run this command we get a different ordering. The reason why we 'zipped' our data poins and labels together is that they are shuffled together. If we shuffled them separately, the correspondance between a data point and its label would be lost."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['12' 'L']\n",
      " ['8' 'H']\n",
      " ['1' 'A']\n",
      " ['11' 'K']\n",
      " ['9' 'I']\n",
      " ['3' 'C']\n",
      " ['13' 'M']\n",
      " ['5' 'E']\n",
      " ['4' 'D']\n",
      " ['10' 'J']\n",
      " ['7' 'G']\n",
      " ['2' 'B']\n",
      " ['6' 'F']]\n"
     ]
    }
   ],
   "source": [
    "np.random.shuffle(dataset)\n",
    "print(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that the label `A` is still associated with the data point 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Producing mini-batches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The python function `range` takes three arguments. The first one defines the staring value of the range. The second defines the end value. The third value defines the number of steps to get from the starting value to the end value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "2\n",
      "4\n",
      "6\n",
      "8\n"
     ]
    }
   ],
   "source": [
    "for i in range(0,10,2):\n",
    "    print (i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, we use the command `list` to display the range."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 2, 4, 6, 8]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(range(0,10,2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In our case, we want the ranges to go from the first data point (index 0), until the last point of our data set, in the increments that are equal to the mini batch size:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 3, 6, 9, 12]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(range(0, data_len, mb_size))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we can take parts of our data and extract them according to the indexes until we reach the end of the list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "mini_batches = [dataset[a:a+mb_size] for a in range(0, data_len, mb_size)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can iterate trought the mini-batches stored in the variable `mini_batches`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 1:\n",
      "[['12' 'L']\n",
      " ['8' 'H']\n",
      " ['1' 'A']]\n",
      "\n",
      "batch 2:\n",
      "[['11' 'K']\n",
      " ['9' 'I']\n",
      " ['3' 'C']]\n",
      "\n",
      "batch 3:\n",
      "[['13' 'M']\n",
      " ['5' 'E']\n",
      " ['4' 'D']]\n",
      "\n",
      "batch 4:\n",
      "[['10' 'J']\n",
      " ['7' 'G']\n",
      " ['2' 'B']]\n",
      "\n",
      "batch 5:\n",
      "[['6' 'F']]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i, batch in enumerate(mini_batches):\n",
    "    print (f'batch {i+1}:\\n{batch}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can use these small datasets as the input of the neural network algorithm in one epoch. In the next epoch, we start by reshuffling our data set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['8' 'H']\n",
      " ['4' 'D']\n",
      " ['11' 'K']\n",
      " ['2' 'B']\n",
      " ['12' 'L']\n",
      " ['6' 'F']\n",
      " ['9' 'I']\n",
      " ['10' 'J']\n",
      " ['13' 'M']\n",
      " ['3' 'C']\n",
      " ['5' 'E']\n",
      " ['7' 'G']\n",
      " ['1' 'A']]\n"
     ]
    }
   ],
   "source": [
    "np.random.shuffle(dataset)\n",
    "print(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we create new mini-batches:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 1:\n",
      "[['8' 'H']\n",
      " ['4' 'D']\n",
      " ['11' 'K']]\n",
      "\n",
      "batch 2:\n",
      "[['2' 'B']\n",
      " ['12' 'L']\n",
      " ['6' 'F']]\n",
      "\n",
      "batch 3:\n",
      "[['9' 'I']\n",
      " ['10' 'J']\n",
      " ['13' 'M']]\n",
      "\n",
      "batch 4:\n",
      "[['3' 'C']\n",
      " ['5' 'E']\n",
      " ['7' 'G']]\n",
      "\n",
      "batch 5:\n",
      "[['1' 'A']]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "mini_batches = [dataset[a:a+mb_size] for a in range(0, data_len, mb_size)]\n",
    "for i, batch in enumerate(mini_batches):\n",
    "    print (f'batch {i+1}:\\n{batch}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This procedure is repeated in every epoch of our neural network training."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
