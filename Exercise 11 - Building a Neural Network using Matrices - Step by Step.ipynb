{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%config InlineBackend.figure_format = 'retina'\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "np.set_printoptions(precision=3)\n",
    "np.set_printoptions(suppress=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Network implementation with Matrices #1: Predefined Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Some additional vector and matrix manipulation functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$A$ is a matrix defined as:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1  3  5 -1]\n",
      " [ 0 -2 -7  3]]\n"
     ]
    }
   ],
   "source": [
    "A = np.array([[1, 3, 5, -1],\n",
    "              [0, -2, -7, 3]])\n",
    "print (A)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is the shape of this matrix:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transform the matrix so that its rows become its columns and the columns its rows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is the shape of the **transposed** matrix A:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "____"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$B$ is a 6-dimensional row vector:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 0 1 0 1 0]\n"
     ]
    }
   ],
   "source": [
    "B = np.array([1,0,1,0,1,0])\n",
    "print (B)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reshape the vector $B$ vector into a $3\\times 2$ matrix:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reshape the vector $B$ vector into a $6\\times 1$ matrix:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Network's Architecture and Data set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The architecture of the network we will implement by using matrices will remain the same as in the previous example, but we will display it by using our new naming convention:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"img/neural_networks_26-new.png\" alt=\"drawing\" width=\"950\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will also use the same dataset we used before:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.array([[ 1.2, 0.7],\n",
    "                 [-0.3,-0.5],\n",
    "                 [ 3.0, 0.1],\n",
    "                 [-0.1,-1.0],\n",
    "                 [-0.0, 1.1],\n",
    "                 [ 2.1,-1.3],\n",
    "                 [ 3.1,-1.8],\n",
    "                 [ 1.1,-0.1],\n",
    "                 [ 1.5,-2.2],\n",
    "                 [ 4.0,-1.0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = np.array([  1,\n",
    "                     0,\n",
    "                     1,\n",
    "                     0,\n",
    "                     0,\n",
    "                     1,\n",
    "                     0,\n",
    "                     1,\n",
    "                     0,\n",
    "                     0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_data(data, labels):\n",
    "    fig = plt.figure(figsize=(5,5))\n",
    "    ax = fig.add_subplot(111)\n",
    "    ax.scatter(data[:,0], data[:,1], c=labels, s=50,  cmap=plt.cm.bwr,zorder=50)\n",
    "    nudge = 0.08\n",
    "    for i, d in enumerate(data):\n",
    "        ax.annotate(f'{i}',(d[0]+nudge,d[1]+nudge))\n",
    "    ax.set_aspect('equal', 'datalim')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 304,
       "width": 316
      },
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_data(data, labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialising neural network layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"img/neural_networks_29.png\" alt=\"drawing\" width=\"400\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Weights of the layer $l_2$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the layer 2 has 3 neurons, and the layer 1 has 2 neurons, this matrix will be of the size $3x2$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\mathbf{W}^{(l_2)}\n",
    "=\n",
    "\\underset{\\mathbf{3x2}}{\n",
    "\\begin{bmatrix}\n",
    "w_{11}^{(l_2)} & w_{12}^{(l_2)}\\\\\n",
    "w_{21}^{(l_2)} & w_{22}^{(l_2)}\\\\\n",
    "w_{31}^{(l_2)} & w_{32}^{(l_2)}\\\\\n",
    "\\end{bmatrix}\\\\\n",
    "}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By using the  _nympy_'s function `randn`, encode the matrix $\\mathbf{W}^{(l_2)}$, fill it with normally distributed random values  and store it in the variable `W_2`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Weights of the layer $l_3$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The layer 3 has 2 neurons and its previous layer ($l_2$) has 3 neurons, thus 3 activations. For this reason, the weight matrix $\\mathbf{W}^{(l_3)}$ will be of the size $2x3$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\\n",
    "\\mathbf{W}^{(l_3)}\n",
    "=\n",
    "\\underset{\\mathbf{2x3}}{\n",
    "\\begin{bmatrix}\n",
    "w_{11}^{(l_3)} & w_{12}^{(l_3)} & w_{13}^{(l_3)}\\\\\n",
    "w_{21}^{(l_3)} & w_{22}^{(l_3)} & w_{23}^{(l_3)}\\\\\n",
    "\\end{bmatrix}\\\\\n",
    "}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Encode the matrix $\\mathbf{W}^{(l_3)}$, fill it with normally distributed random values  and store it in the variable `W_3`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Biases"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"img/neural_networks_30.png\" alt=\"drawing\" width=\"400\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Biases of the layer $l_2$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the layer 2 has 3 neurons, this matrix will be of the size $3x1$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\mathbf{b}^{(l_2)}\n",
    "=\n",
    "\\underset{\\mathbf{3x1}}{\n",
    "\\begin{bmatrix}\n",
    "b_{1}^{(l_2)}\\\\\n",
    "b_{2}^{(l_2)}\\\\\n",
    "b_{3}^{(l_2)}\\\\\n",
    "\\end{bmatrix}\\\\\n",
    "}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By using the  _nympy_'s function `random.randn`, encode the vector $\\mathbf{b}^{(l_2)}$, fill it with normally distributed random values  and store it in the variable `b_2`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Biases of the layer $l_3$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the third layer has two neurons, it will also have 2 biases:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\mathbf{b}^{(l_3)}\n",
    "=\n",
    "\\underset{\\mathbf{2x1}}{\n",
    "\\begin{bmatrix}\n",
    "b_{1}^{(l_3)}\\\\\n",
    "b_{2}^{(l_3)}\\\\\n",
    "\\end{bmatrix}\\\\\n",
    "}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Encode the vector $\\mathbf{b}^{(l_3)}$, fill it with normally distributed random values  and store it in the variable `b_3`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Activations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"img/neural_networks_31.png\" alt=\"drawing\" width=\"400\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Activations of the layer $l_1$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\mathbf{a}^{(l_1)}\n",
    "=\n",
    "\\underset{\\mathbf{2x1}}{\n",
    "\\begin{bmatrix}\n",
    "a_{1}^{(l_1)}\\\\\n",
    "a_{2}^{(l_1)}\\\\\n",
    "\\end{bmatrix}\\\\\n",
    "}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Encode the vector $\\mathbf{a}^{(l_1)}$, fill it with the coordinates of the first data point `[1.2, 0.7]` and store it in the variable `a_1`. You can use array reshape and/or transpose functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Activations of the layer $l_2$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To compute the weighted sum for the layer 2, we can use the following formula:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{align*}  \n",
    "\\underset{\\mathbf{3x1}}{\n",
    "\\begin{bmatrix}\n",
    "z_1^{(l_2)}\\\\\n",
    "z_2^{(l_2)}\\\\\n",
    "z_3^{(l_2)}\\\\\n",
    "\\end{bmatrix}}\n",
    "&=\n",
    "\\underset{\\mathbf{3x2}}{\n",
    "\\begin{bmatrix}\n",
    "w_{11}^{(l_2)} & w_{12}^{(l_2)}\\\\\n",
    "w_{21}^{(l_2)} & w_{22}^{(l_2)}\\\\\n",
    "w_{31}^{(l_2)} & w_{32}^{(l_2)}\\\\\n",
    "\\end{bmatrix}\\\\\n",
    "}\n",
    "\\times\n",
    "\\underset{\\mathbf{2x1}}{\n",
    "\\begin{bmatrix}\n",
    "a_{1}^{(l_1)}\\\\\n",
    "a_{2}^{(l_1)}\\\\\n",
    "\\end{bmatrix}\\\\\n",
    "}\n",
    "+\n",
    "\\underset{\\mathbf{3x1}}{\n",
    "\\begin{bmatrix}\n",
    "b_{1}^{(l_2)}\\\\\n",
    "b_{2}^{(l_2)}\\\\\n",
    "b_{3}^{(l_2)}\\\\\n",
    "\\end{bmatrix}\\\\\n",
    "}\\\\\\\\\n",
    "\\end{align*}  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\mathbf{z}^{(l_2)}=\\mathbf{W}^{(l_2)}\\cdot \\mathbf{a}^{(l_1)}+\\mathbf{b}^{(l_2)}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute the vector containing the weighted sums of the layer 2 and store it in the variable`z_2`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To compute the activations, of the layer 2we just need to apply sigmoid activation to the matrix $\\mathbf{z}^{(l_2)}$ `(z_2)`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\mathbf{a}^{(l_2)}\n",
    "\\equiv\n",
    "\\begin{bmatrix}\n",
    "a_{1}^{(l_2)}\\\\\n",
    "a_{2}^{(l_2)}\\\\\n",
    "a_{3}^{(l_2)}\\\\\n",
    "\\end{bmatrix}\n",
    "=\n",
    "\\sigma(\\mathbf{z}^{(l_2)})\n",
    "\\equiv\n",
    "\\sigma\n",
    "\\left(\\;\n",
    "\\begin{bmatrix}\n",
    "z_{1}^{(l_2)}\\\\\n",
    "z_{2}^{(l_2)}\\\\\n",
    "z_{3}^{(l_2)}\\\\\n",
    "\\end{bmatrix}\\;\n",
    "\\right)\n",
    "\\equiv\n",
    "\\begin{bmatrix}\n",
    "\\sigma(z_1^{(l_2)})\\\\\n",
    "\\sigma(z_2^{(l_2)})\\\\\n",
    "\\sigma(z_3^{(l_2)})\\\\\n",
    "\\end{bmatrix}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the sigmoid function that takes vector input:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute the activations of the second layer,  $\\mathbf{a}^{(l_2)}$ and store it in the variable `a_2`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Activations of the layer $l_3$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To compute the activations for the layer 3, we apply the same procedure we did for the level 2. To compute the weighted average matrix of the layer 3 we compute a matrix product of the weight matrix of the layer 3 with the activation matrix of the layer before (layer 2), and add the bias matrix of the level 3:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{align*}  \n",
    "\\underset{\\mathbf{2x1}}{\n",
    "\\begin{bmatrix}\n",
    "z_1^{(l_3)}\\\\\n",
    "z_2^{(l_3)}\\\\\n",
    "\\end{bmatrix}}\n",
    "&=\n",
    "\\underset{\\mathbf{2x3}}{\n",
    "\\begin{bmatrix}\n",
    "w_{11}^{(l_3)} & w_{12}^{(l_3)} & w_{13}^{(l_3)}\\\\\n",
    "w_{21}^{(l_3)} & w_{22}^{(l_3)} & w_{23}^{(l_3)}\\\\\n",
    "\\end{bmatrix}\\\\\n",
    "}\n",
    "\\times\n",
    "\\underset{\\mathbf{3x1}}{\n",
    "\\begin{bmatrix}\n",
    "a_{1}^{(l_2)}\\\\\n",
    "a_{2}^{(l_2)}\\\\\n",
    "a_{3}^{(l_2)}\\\\\n",
    "\\end{bmatrix}\\\\\n",
    "}\n",
    "+\n",
    "\\underset{\\mathbf{2x1}}{\n",
    "\\begin{bmatrix}\n",
    "b_{1}^{(l_3)}\\\\\n",
    "b_{2}^{(l_3)}\\\\\n",
    "\\end{bmatrix}\\\\\n",
    "}\\\\\\\\\n",
    "\\end{align*} "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\mathbf{z}^{(l_3)}=\\mathbf{W}^{(l_3)}\\times \\mathbf{a}^{(l_2)}+\\mathbf{b}^{(l_3)}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute the vector containing the weighted sums of the layer 3 and store it in the variable`z_3`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To compute the final activation of the layer 3 (output layer), we apply the sigmoid function to the weighted average:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\mathbf{a}^{(l_3)}\n",
    "\\equiv\n",
    "\\begin{bmatrix}\n",
    "a_{1}^{(l_3)}\\\\\n",
    "a_{2}^{(l_3)}\\\\\n",
    "\\end{bmatrix}\n",
    "=\n",
    "\\sigma(\\mathbf{z}^{(l_3)})\n",
    "\\equiv\n",
    "\\begin{bmatrix}\n",
    "\\sigma(z_1^{(l_3)})\\\\\n",
    "\\sigma(z_2^{(l_3)})\\\\\n",
    "\\end{bmatrix}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute the activations of the third layer, $\\mathbf{a}^{(l_3)}$ and store it in the variable `a_3`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cost function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " The data point we were using to compute the forward pass contains coordinates `[1.2, 0.7]` , and it is associated with the label `1`. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we have seen in the previous case, we need to interpret the data labels `1` and `0` by means of 2 neurons. The output of the first neuron encodes the probability that the label is `1`, and the second the probability that the label is `0`. In the last exercise, we used the function `convert_label` to convert the labels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_label(label):\n",
    "    if (label == 1):\n",
    "        return (1,0)\n",
    "    if (label == 0):\n",
    "        return (0,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1],\n",
       "       [0]])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "convert_label(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0],\n",
       "       [1]])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "convert_label(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Redefine the function `convert_label`to output column vectors of probabilities:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert the label associated with the first data point `[1.2, 0.7]`, and store it into the variable `y`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, we will be using the _quadratic cost function_ to compute the cost of our example. Since we have two output layers, the formula for computing the cost of a single training example we will be:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "TC = (a_1^{(l_3)}-y_1)^2+(a_2^{(l_3)}-y_2)^2\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This means that we need to substract the activation of each neuron in the output layer from the true label associated with this neuron, square it and sum the squared terms. This same equation can be represented in simpler terms by using vectors:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "TC =\\|a^{(l_3)}-y \\|^2\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute the total cost and store it in the variable `TC`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Computing the backward pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Computing the derivatives of the cost function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The computation of the partial derivatives in $\\frac{\\partial C_x}{\\partial a^{(l_3)}}$ boils down to a difference between two column vectors:\n",
    "\n",
    "$$\\frac{\\partial TC}{\\partial a^{(l_3)}} = 2(a^{(l_3)}-y)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute $\\frac{\\partial TC}{\\partial a^{(l_3)}}$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We rename the partial derivates of the total cost in terms of the weighted sums $\\frac{\\partial TC}{\\partial z^{(l_3)}}$ and $\\frac{\\partial TC}{\\partial z^{(l_2)}}$ store them in the following vectors:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\delta^{(l_3)}\n",
    "=\n",
    "\\begin{bmatrix}\n",
    "\\delta_1^{(l_3)}\\\\\n",
    "\\delta_2^{(l_3)}\\\\\n",
    "\\end{bmatrix};\\quad\n",
    "\\delta^{(l_2)}\n",
    "=\n",
    "\\begin{bmatrix}\n",
    "\\delta_1^{(l_2)}\\\\\n",
    "\\delta_2^{(l_2)}\\\\\n",
    "\\delta_3^{(l_2)}\\\\\n",
    "\\end{bmatrix};\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Computing the derivatives of the  weighted sums in the output layer $\\delta^{(l_3)}$:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Computing the $\\delta^{(l_3)}$ is described using the previously defined formula: <br> <br>\n",
    "$$\n",
    "\\delta^{(l_3)}=2\\left(\\mathbf{a}^{(l_3)}-\\mathbf{y}\\right)\\odot \\mathbf{a}^{(l_3)} \\odot \\left(\\mathbf{1}-\\mathbf{a}^{(l_3)}\\right) \n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute $\\delta^{(l_3)}$ and store it in a variable `delta_3`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Computing the derivatives of the weighted sums in the hidden layer $\\delta^{(l_2)}$:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Computing the $\\delta^{(l_2)}$ is described using the previously defined formula: <br> <br>\n",
    "$$\\delta^{(l_2)}=\\mathbf{a}^{(l_2)}\\left(1-\\mathbf{a}^{(l_2)}\\right)\\odot \\mathbf{W^T}^{(l_3)} \\cdot \\mathbf{\\delta}^{(l_3)}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute $\\delta^{(l_2)}$ and store it in a variable `delta_2`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Computing the derivatives of the biases in the output layer $\\mathbf{b}^{(l_3)}$:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once we know the partial derivatives of the cost in respect to the weighted averages, computing the biases is trivial. Since a bias is only added to the multiplications of weights and activations, its derivative is equal to 1. Therefore, the biases of a certain layer have the same value as the weighted averages of that layer:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute the vector containing partial derivatives of the total cost in terms of biases of the third layer, and store it in the variable `db_3`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Computing the derivatives of the biases of the hidden layer $\\mathbf{b}^{(l_2)}$:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute the vector containing partial derivatives of the total cost in terms of biases of the second layer, and store it in the variable `db_2`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Computing the derivatives of the weights in the output layer $\\mathbf{W}^{(l_3)}$:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can compute the matrix product of the already computed weighted average of the layer 3 and this transposed activation matrix:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\begin{align*}\n",
    "\\partial \\mathbf{W}^{(l_3)}=\n",
    "\\delta^{(l_3)}\\cdot\\left(a^{(l_2)}\\right)^T\n",
    "&=\n",
    "\\underset{\\mathbf{2x1}}{\n",
    "\\begin{bmatrix}\n",
    "\\delta_1^{(l_3)}\\\\\n",
    "\\delta_2^{(l_3)}\\\\\n",
    "\\end{bmatrix}}\n",
    "\\cdot\n",
    "\\underset{\\mathbf{1x3}}{\n",
    "\\begin{bmatrix}\n",
    "a_{1}^{(l_2)} & a_{2}^{(l_2)} & a_{3}^{(l_2)}\n",
    "\\end{bmatrix}}\\\\\\\\\n",
    "&=\n",
    "\\underset{\\mathbf{2x3}}{\n",
    "\\begin{bmatrix}\n",
    "\\delta_1^{(l_3)} a_{1}^{(l_2)} & \\delta_1^{(l_3)} a_{2}^{(l_2)} & \\delta_1^{(l_3)} a_{3}^{(l_2)} \\\\\n",
    "\\delta_2^{(l_3)} a_{1}^{(l_2)} & \\delta_2^{(l_3)} a_{2}^{(l_2)} & \\delta_2^{(l_3)} a_{3}^{(l_2)} \\\\\n",
    "\\end{bmatrix}}\\\\\n",
    "\\end{align*}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute the vector containing partial derivatives of the total cost in terms of weights of the third layer, and store it in the variable `dW_3`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Computing the derivatives of the weights in the hidden layer $\\mathbf{W}^{(l_2)}$:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can compute the dot product of the already computed weighted average of the layer 2 and this transposed activation matrix:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\begin{align*}\n",
    "\\partial \\mathbf{W}^{(l_2)}=\n",
    "\\delta^{(l_2)}\\cdot\\left(a^{(l_1)}\\right)^T\n",
    "&=\n",
    "\\underset{\\mathbf{3x1}}{\n",
    "\\begin{bmatrix}\n",
    "\\delta_1^{(l_2)}\\\\\n",
    "\\delta_2^{(l_2)}\\\\\n",
    "\\delta_3^{(l_2)}\\\\\n",
    "\\end{bmatrix}}\n",
    "\\cdot\n",
    "\\underset{\\mathbf{1x2}}{\n",
    "\\begin{bmatrix}\n",
    "a_{1}^{(l_2)} & a_{2}^{(l_2)}\n",
    "\\end{bmatrix}}\\\\\\\\\n",
    "&=\n",
    "\\underset{\\mathbf{3x2}}{\n",
    "\\begin{bmatrix}\n",
    "\\delta_1^{(l_3)} a_{1}^{(l_2)} & \\delta_1^{(l_3)} a_{2}^{(l_2)} \\\\\n",
    "\\delta_2^{(l_3)} a_{1}^{(l_2)} & \\delta_2^{(l_3)} a_{2}^{(l_2)} \\\\\n",
    "\\delta_3^{(l_3)} a_{1}^{(l_2)} & \\delta_3^{(l_3)} a_{2}^{(l_2)}\n",
    "\\end{bmatrix}}\\\\\n",
    "\\end{align*}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute the vector containing partial derivatives of the total cost in terms of weights of the second layer, and store it in the variable `dW_2`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Updating the weights and the biases of the neural network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Introduce the variable `step_size`, initialise it with a small value, and update the weights and biases:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What we want to achieve with training is that our network outputs the value as close as possible to the label, which the data is associated with. Print the current label:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print the activation vector of the last layer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute the new activation of the last layer by computing the forward pass again with the updated weights and biases:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute the cost/loss, and store it in the variable `TC_new`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare the old cost, and the new cost:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
