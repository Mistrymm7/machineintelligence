{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%config InlineBackend.figure_format = 'retina'\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "import numpy as np\n",
    "np.set_printoptions(precision=3)\n",
    "np.set_printoptions(suppress=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classifying hand-written digits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the MNIST data set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this document, we will use both our own neural network algorithm, and Tensorflow library. To make it easier for people using Google Colab to follow, we will load the data set from the TensorFlow library that comes preinstalled with colab. Users loading these notebooks in their own environments will have to install Tensorflow anyways."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we import the TensorFlow library as `tf`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we load the MNIST dataset as `mnist`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.datasets import mnist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the function `load_data`, we will load the dataset into the variable `dataset`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = mnist.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can further unpack our dataset into 4 variables containing training and validation data and labels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "(train_data, train_labels), (validation_data, validation_labels) = dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the length/shape of our training and validation data and labels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000,)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 28, 28)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000,)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation_labels.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since this dataset does not have the testing set, create one from the training set by taking 10000 points from it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = train_data[-10000:]\n",
    "train_data = train_data[:50000]\n",
    "test_labels = train_labels[-10000:]\n",
    "train_labels = train_labels[:50000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print the shape of the testing set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 28, 28)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000,)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_labels.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploring the MNIST data set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print the shape of the first training data point:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28, 28)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following function visualises the matrix of numbers as an image. Visualise some other data points:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 248,
       "width": 251
      },
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(train_data[50], cmap=cm.Greys)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the selected training data point, print the corresponding label:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels[50]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print the labels of the first 100 training data points:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5, 0, 4, 1, 9, 2, 1, 3, 1, 4, 3, 5, 3, 6, 1, 7, 2, 8, 6, 9, 4, 0,\n",
       "       9, 1, 1, 2, 4, 3, 2, 7, 3, 8, 6, 9, 0, 5, 6, 0, 7, 6, 1, 8, 7, 9,\n",
       "       3, 9, 8, 5, 9, 3, 3, 0, 7, 4, 9, 8, 0, 9, 4, 1, 4, 4, 6, 0, 4, 5,\n",
       "       6, 1, 0, 0, 1, 7, 1, 6, 3, 0, 2, 1, 1, 7, 9, 0, 2, 6, 7, 8, 3, 9,\n",
       "       0, 4, 6, 7, 4, 6, 8, 0, 7, 8, 3, 1], dtype=uint8)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels[:100]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print the values of 14th row of the first training data point:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  35,\n",
       "       241, 225, 160, 108,   1,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0], dtype=uint8)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[0][13]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print the values of the 8th column of the first data point:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  0,   0,   0,   0,   0,   0,   0,  49, 238, 253, 253, 253, 253,\n",
       "       253, 253, 253, 253, 251,  93,  82,  82,  56,  39,   0,   0,   0,\n",
       "         0,   0], dtype=uint8)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[0][:][7]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalising the values in the MNIST data set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find the maximum value in our data set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "255"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normalise the values of all data sets between 0 and 1:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = train_data / 255\n",
    "validation_data = validation_data / 255\n",
    "test_data = test_data / 255"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print the values of 14th row of the first training data point:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   ,\n",
       "       0.   , 0.   , 0.   , 0.137, 0.945, 0.882, 0.627, 0.424, 0.004,\n",
       "       0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   ,\n",
       "       0.   ])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[0][13]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reshaping the values in the MNIST data set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print the shape of the first data point in the training set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28, 28)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reshape this data point into a column vector and store it in a variable `dp`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.   ],\n",
       "       [0.   ],\n",
       "       [0.   ],\n",
       "       [0.   ],\n",
       "       [0.   ],\n",
       "       [0.   ],\n",
       "       [0.   ],\n",
       "       [0.   ],\n",
       "       [0.   ],\n",
       "       [0.   ],\n",
       "       [0.   ],\n",
       "       [0.   ],\n",
       "       [0.   ],\n",
       "       [0.   ],\n",
       "       [0.   ],\n",
       "       [0.   ],\n",
       "       [0.   ],\n",
       "       [0.   ],\n",
       "       [0.   ],\n",
       "       [0.   ],\n",
       "       [0.   ],\n",
       "       [0.   ],\n",
       "       [0.   ],\n",
       "       [0.   ],\n",
       "       [0.   ],\n",
       "       [0.   ],\n",
       "       [0.   ],\n",
       "       [0.   ],\n",
       "       [0.   ],\n",
       "       [0.   ],\n",
       "       [0.   ],\n",
       "       [0.   ],\n",
       "       [0.   ],\n",
       "       [0.   ],\n",
       "       [0.   ],\n",
       "       [0.   ],\n",
       "       [0.   ],\n",
       "       [0.   ],\n",
       "       [0.   ],\n",
       "       [0.   ],\n",
       "       [0.   ],\n",
       "       [0.   ],\n",
       "       [0.   ],\n",
       "       [0.   ],\n",
       "       [0.   ],\n",
       "       [0.   ],\n",
       "       [0.   ],\n",
       "       [0.   ],\n",
       "       [0.   ],\n",
       "       [0.   ],\n",
       "       [0.   ],\n",
       "       [0.   ],\n",
       "       [0.   ],\n",
       "       [0.   ],\n",
       "       [0.   ],\n",
       "       [0.   ],\n",
       "       [0.   ],\n",
       "       [0.   ],\n",
       "       [0.   ],\n",
       "       [0.   ],\n",
       "       [0.   ],\n",
       "       [0.   ],\n",
       "       [0.   ],\n",
       "       [0.   ],\n",
       "       [0.   ],\n",
       "       [0.   ],\n",
       "       [0.   ],\n",
       "       [0.   ],\n",
       "       [0.   ],\n",
       "       [0.   ],\n",
       "       [0.   ],\n",
       "       [0.   ],\n",
       "       [0.   ],\n",
       "       [0.   ],\n",
       "       [0.   ],\n",
       "       [0.   ],\n",
       "       [0.   ],\n",
       "       [0.   ],\n",
       "       [0.   ],\n",
       "       [0.   ],\n",
       "       [0.   ],\n",
       "       [0.   ],\n",
       "       [0.   ],\n",
       "       [0.   ],\n",
       "       [0.   ],\n",
       "       [0.   ],\n",
       "       [0.   ],\n",
       "       [0.   ],\n",
       "       [0.   ],\n",
       "       [0.   ],\n",
       "       [0.   ],\n",
       "       [0.   ],\n",
       "       [0.   ],\n",
       "       [0.   ],\n",
       "       [0.   ],\n",
       "       [0.   ],\n",
       "       [0.   ],\n",
       "       [0.   ],\n",
       "       [0.   ],\n",
       "       [0.   ],\n",
       "       [0.   ],\n",
       "       [0.   ],\n",
       "       [0.   ],\n",
       "       [0.   ],\n",
       "       [0.   ],\n",
       "       [0.   ],\n",
       "       [0.   ],\n",
       "       [0.   ],\n",
       "       [0.   ],\n",
       "       [0.   ],\n",
       "       [0.   ],\n",
       "       [0.   ],\n",
       "       [0.   ],\n",
       "       [0.   ],\n",
       "       [0.   ],\n",
       "       [0.   ],\n",
       "       [0.   ],\n",
       "       [0.   ],\n",
       "       [0.   ],\n",
       "       [0.   ],\n",
       "       [0.   ],\n",
       "       [0.   ],\n",
       "       [0.   ],\n",
       "       [0.   ],\n",
       "       [0.   ],\n",
       "       [0.   ],\n",
       "       [0.   ],\n",
       "       [0.   ],\n",
       "       [0.   ],\n",
       "       [0.   ],\n",
       "       [0.   ],\n",
       "       [0.   ],\n",
       "       [0.   ],\n",
       "       [0.   ],\n",
       "       [0.   ],\n",
       "       [0.   ],\n",
       "       [0.   ],\n",
       "       [0.   ],\n",
       "       [0.   ],\n",
       "       [0.   ],\n",
       "       [0.   ],\n",
       "       [0.   ],\n",
       "       [0.   ],\n",
       "       [0.   ],\n",
       "       [0.   ],\n",
       "       [0.   ],\n",
       "       [0.   ],\n",
       "       [0.   ],\n",
       "       [0.   ],\n",
       "       [0.   ],\n",
       "       [0.   ],\n",
       "       [0.   ],\n",
       "       [0.012],\n",
       "       [0.071],\n",
       "       [0.071],\n",
       "       [0.071],\n",
       "       [0.494],\n",
       "       [0.533],\n",
       "       [0.686],\n",
       "       [0.102],\n",
       "       [0.651],\n",
       "       [1.   ],\n",
       "       [0.969],\n",
       "       [0.498],\n",
       "       [0.   ],\n",
       "       [0.   ],\n",
       "       [0.   ],\n",
       "       [0.   ],\n",
       "       [0.   ],\n",
       "       [0.   ],\n",
       "       [0.   ],\n",
       "       [0.   ],\n",
       "       [0.   ],\n",
       "       [0.   ],\n",
       "       [0.   ],\n",
       "       [0.   ],\n",
       "       [0.118],\n",
       "       [0.141],\n",
       "       [0.369],\n",
       "       [0.604],\n",
       "       [0.667],\n",
       "       [0.992],\n",
       "       [0.992],\n",
       "       [0.992],\n",
       "       [0.992],\n",
       "       [0.992],\n",
       "       [0.882],\n",
       "       [0.675],\n",
       "       [0.992],\n",
       "       [0.949],\n",
       "       [0.765],\n",
       "       [0.251],\n",
       "       [0.   ],\n",
       "       [0.   ],\n",
       "       [0.   ],\n",
       "       [0.   ],\n",
       "       [0.   ],\n",
       "       [0.   ],\n",
       "       [0.   ],\n",
       "       [0.   ],\n",
       "       [0.   ],\n",
       "       [0.   ],\n",
       "       [0.   ],\n",
       "       [0.192],\n",
       "       [0.933],\n",
       "       [0.992],\n",
       "       [0.992],\n",
       "       [0.992],\n",
       "       [0.992],\n",
       "       [0.992],\n",
       "       [0.992],\n",
       "       [0.992],\n",
       "       [0.992],\n",
       "       [0.984],\n",
       "       [0.365],\n",
       "       [0.322],\n",
       "       [0.322],\n",
       "       [0.22 ],\n",
       "       [0.153],\n",
       "       [0.   ],\n",
       "       [0.   ],\n",
       "       [0.   ],\n",
       "       [0.   ],\n",
       "       [0.   ],\n",
       "       [0.   ],\n",
       "       [0.   ],\n",
       "       [0.   ],\n",
       "       [0.   ],\n",
       "       [0.   ],\n",
       "       [0.   ],\n",
       "       [0.   ],\n",
       "       [0.071],\n",
       "       [0.859],\n",
       "       [0.992],\n",
       "       [0.992],\n",
       "       [0.992],\n",
       "       [0.992],\n",
       "       [0.992],\n",
       "       [0.776],\n",
       "       [0.714],\n",
       "       [0.969],\n",
       "       [0.945],\n",
       "       [0.   ],\n",
       "       [0.   ],\n",
       "       [0.   ],\n",
       "       [0.   ],\n",
       "       [0.   ],\n",
       "       [0.   ],\n",
       "       [0.   ],\n",
       "       [0.   ],\n",
       "       [0.   ],\n",
       "       [0.   ],\n",
       "       [0.   ],\n",
       "       [0.   ],\n",
       "       [0.   ],\n",
       "       [0.   ],\n",
       "       [0.   ],\n",
       "       [0.   ],\n",
       "       [0.   ],\n",
       "       [0.   ],\n",
       "       [0.314],\n",
       "       [0.612],\n",
       "       [0.42 ],\n",
       "       [0.992],\n",
       "       [0.992],\n",
       "       [0.804],\n",
       "       [0.043],\n",
       "       [0.   ],\n",
       "       [0.169],\n",
       "       [0.604],\n",
       "       [0.   ],\n",
       "       [0.   ],\n",
       "       [0.   ],\n",
       "       [0.   ],\n",
       "       [0.   ],\n",
       "       [0.   ],\n",
       "       [0.   ],\n",
       "       [0.   ],\n",
       "       [0.   ],\n",
       "       [0.   ],\n",
       "       [0.   ],\n",
       "       [0.   ],\n",
       "       [0.   ],\n",
       "       [0.   ],\n",
       "       [0.   ],\n",
       "       [0.   ],\n",
       "       [0.   ],\n",
       "       [0.   ],\n",
       "       [0.   ],\n",
       "       [0.055],\n",
       "       [0.004],\n",
       "       [0.604],\n",
       "       [0.992],\n",
       "       [0.353],\n",
       "       [0.   ],\n",
       "       [0.   ],\n",
       "       [0.   ],\n",
       "       [0.   ],\n",
       "       [0.   ],\n",
       "       [0.   ],\n",
       "       [0.   ],\n",
       "       [0.   ],\n",
       "       [0.   ],\n",
       "       [0.   ],\n",
       "       [0.   ],\n",
       "       [0.   ],\n",
       "       [0.   ],\n",
       "       [0.   ],\n",
       "       [0.   ],\n",
       "       [0.   ],\n",
       "       [0.   ],\n",
       "       [0.   ],\n",
       "       [0.   ],\n",
       "       [0.   ],\n",
       "       [0.   ],\n",
       "       [0.   ],\n",
       "       [0.   ],\n",
       "       [0.   ],\n",
       "       [0.   ],\n",
       "       [0.545],\n",
       "       [0.992],\n",
       "       [0.745],\n",
       "       [0.008],\n",
       "       [0.   ],\n",
       "       [0.   ],\n",
       "       [0.   ],\n",
       "       [0.   ],\n",
       "       [0.   ],\n",
       "       [0.   ],\n",
       "       [0.   ],\n",
       "       [0.   ],\n",
       "       [0.   ],\n",
       "       [0.   ],\n",
       "       [0.   ],\n",
       "       [0.   ],\n",
       "       [0.   ],\n",
       "       [0.   ],\n",
       "       [0.   ],\n",
       "       [0.   ],\n",
       "       [0.   ],\n",
       "       [0.   ],\n",
       "       [0.   ],\n",
       "       [0.   ],\n",
       "       [0.   ],\n",
       "       [0.   ],\n",
       "       [0.   ],\n",
       "       [0.   ],\n",
       "       [0.043],\n",
       "       [0.745],\n",
       "       [0.992],\n",
       "       [0.275],\n",
       "       [0.   ],\n",
       "       [0.   ],\n",
       "       [0.   ],\n",
       "       [0.   ],\n",
       "       [0.   ],\n",
       "       [0.   ],\n",
       "       [0.   ],\n",
       "       [0.   ],\n",
       "       [0.   ],\n",
       "       [0.   ],\n",
       "       [0.   ],\n",
       "       [0.   ],\n",
       "       [0.   ],\n",
       "       [0.   ],\n",
       "       [0.   ],\n",
       "       [0.   ],\n",
       "       [0.   ],\n",
       "       [0.   ],\n",
       "       [0.   ],\n",
       "       [0.   ],\n",
       "       [0.   ],\n",
       "       [0.   ],\n",
       "       [0.   ],\n",
       "       [0.   ],\n",
       "       [0.   ],\n",
       "       [0.137],\n",
       "       [0.945],\n",
       "       [0.882],\n",
       "       [0.627],\n",
       "       [0.424],\n",
       "       [0.004],\n",
       "       [0.   ],\n",
       "       [0.   ],\n",
       "       [0.   ],\n",
       "       [0.   ],\n",
       "       [0.   ],\n",
       "       [0.   ],\n",
       "       [0.   ],\n",
       "       [0.   ],\n",
       "       [0.   ],\n",
       "       [0.   ],\n",
       "       [0.   ],\n",
       "       [0.   ],\n",
       "       [0.   ],\n",
       "       [0.   ],\n",
       "       [0.   ],\n",
       "       [0.   ],\n",
       "       [0.   ],\n",
       "       [0.   ],\n",
       "       [0.   ],\n",
       "       [0.   ],\n",
       "       [0.   ],\n",
       "       [0.   ],\n",
       "       [0.   ],\n",
       "       [0.318],\n",
       "       [0.941],\n",
       "       [0.992],\n",
       "       [0.992],\n",
       "       [0.467],\n",
       "       [0.098],\n",
       "       [0.   ],\n",
       "       [0.   ],\n",
       "       [0.   ],\n",
       "       [0.   ],\n",
       "       [0.   ],\n",
       "       [0.   ],\n",
       "       [0.   ],\n",
       "       [0.   ],\n",
       "       [0.   ],\n",
       "       [0.   ],\n",
       "       [0.   ],\n",
       "       [0.   ],\n",
       "       [0.   ],\n",
       "       [0.   ],\n",
       "       [0.   ],\n",
       "       [0.   ],\n",
       "       [0.   ],\n",
       "       [0.   ],\n",
       "       [0.   ],\n",
       "       [0.   ],\n",
       "       [0.   ],\n",
       "       [0.   ],\n",
       "       [0.   ],\n",
       "       [0.176],\n",
       "       [0.729],\n",
       "       [0.992],\n",
       "       [0.992],\n",
       "       [0.588],\n",
       "       [0.106],\n",
       "       [0.   ],\n",
       "       [0.   ],\n",
       "       [0.   ],\n",
       "       [0.   ],\n",
       "       [0.   ],\n",
       "       [0.   ],\n",
       "       [0.   ],\n",
       "       [0.   ],\n",
       "       [0.   ],\n",
       "       [0.   ],\n",
       "       [0.   ],\n",
       "       [0.   ],\n",
       "       [0.   ],\n",
       "       [0.   ],\n",
       "       [0.   ],\n",
       "       [0.   ],\n",
       "       [0.   ],\n",
       "       [0.   ],\n",
       "       [0.   ],\n",
       "       [0.   ],\n",
       "       [0.   ],\n",
       "       [0.   ],\n",
       "       [0.   ],\n",
       "       [0.063],\n",
       "       [0.365],\n",
       "       [0.988],\n",
       "       [0.992],\n",
       "       [0.733],\n",
       "       [0.   ],\n",
       "       [0.   ],\n",
       "       [0.   ],\n",
       "       [0.   ],\n",
       "       [0.   ],\n",
       "       [0.   ],\n",
       "       [0.   ],\n",
       "       [0.   ],\n",
       "       [0.   ],\n",
       "       [0.   ],\n",
       "       [0.   ],\n",
       "       [0.   ],\n",
       "       [0.   ],\n",
       "       [0.   ],\n",
       "       [0.   ],\n",
       "       [0.   ],\n",
       "       [0.   ],\n",
       "       [0.   ],\n",
       "       [0.   ],\n",
       "       [0.   ],\n",
       "       [0.   ],\n",
       "       [0.   ],\n",
       "       [0.   ],\n",
       "       [0.   ],\n",
       "       [0.   ],\n",
       "       [0.976],\n",
       "       [0.992],\n",
       "       [0.976],\n",
       "       [0.251],\n",
       "       [0.   ],\n",
       "       [0.   ],\n",
       "       [0.   ],\n",
       "       [0.   ],\n",
       "       [0.   ],\n",
       "       [0.   ],\n",
       "       [0.   ],\n",
       "       [0.   ],\n",
       "       [0.   ],\n",
       "       [0.   ],\n",
       "       [0.   ],\n",
       "       [0.   ],\n",
       "       [0.   ],\n",
       "       [0.   ],\n",
       "       [0.   ],\n",
       "       [0.   ],\n",
       "       [0.   ],\n",
       "       [0.   ],\n",
       "       [0.   ],\n",
       "       [0.   ],\n",
       "       [0.   ],\n",
       "       [0.18 ],\n",
       "       [0.51 ],\n",
       "       [0.718],\n",
       "       [0.992],\n",
       "       [0.992],\n",
       "       [0.812],\n",
       "       [0.008],\n",
       "       [0.   ],\n",
       "       [0.   ],\n",
       "       [0.   ],\n",
       "       [0.   ],\n",
       "       [0.   ],\n",
       "       [0.   ],\n",
       "       [0.   ],\n",
       "       [0.   ],\n",
       "       [0.   ],\n",
       "       [0.   ],\n",
       "       [0.   ],\n",
       "       [0.   ],\n",
       "       [0.   ],\n",
       "       [0.   ],\n",
       "       [0.   ],\n",
       "       [0.   ],\n",
       "       [0.   ],\n",
       "       [0.   ],\n",
       "       [0.   ],\n",
       "       [0.153],\n",
       "       [0.58 ],\n",
       "       [0.898],\n",
       "       [0.992],\n",
       "       [0.992],\n",
       "       [0.992],\n",
       "       [0.98 ],\n",
       "       [0.714],\n",
       "       [0.   ],\n",
       "       [0.   ],\n",
       "       [0.   ],\n",
       "       [0.   ],\n",
       "       [0.   ],\n",
       "       [0.   ],\n",
       "       [0.   ],\n",
       "       [0.   ],\n",
       "       [0.   ],\n",
       "       [0.   ],\n",
       "       [0.   ],\n",
       "       [0.   ],\n",
       "       [0.   ],\n",
       "       [0.   ],\n",
       "       [0.   ],\n",
       "       [0.   ],\n",
       "       [0.   ],\n",
       "       [0.   ],\n",
       "       [0.094],\n",
       "       [0.447],\n",
       "       [0.867],\n",
       "       [0.992],\n",
       "       [0.992],\n",
       "       [0.992],\n",
       "       [0.992],\n",
       "       [0.788],\n",
       "       [0.306],\n",
       "       [0.   ],\n",
       "       [0.   ],\n",
       "       [0.   ],\n",
       "       [0.   ],\n",
       "       [0.   ],\n",
       "       [0.   ],\n",
       "       [0.   ],\n",
       "       [0.   ],\n",
       "       [0.   ],\n",
       "       [0.   ],\n",
       "       [0.   ],\n",
       "       [0.   ],\n",
       "       [0.   ],\n",
       "       [0.   ],\n",
       "       [0.   ],\n",
       "       [0.   ],\n",
       "       [0.   ],\n",
       "       [0.09 ],\n",
       "       [0.259],\n",
       "       [0.835],\n",
       "       [0.992],\n",
       "       [0.992],\n",
       "       [0.992],\n",
       "       [0.992],\n",
       "       [0.776],\n",
       "       [0.318],\n",
       "       [0.008],\n",
       "       [0.   ],\n",
       "       [0.   ],\n",
       "       [0.   ],\n",
       "       [0.   ],\n",
       "       [0.   ],\n",
       "       [0.   ],\n",
       "       [0.   ],\n",
       "       [0.   ],\n",
       "       [0.   ],\n",
       "       [0.   ],\n",
       "       [0.   ],\n",
       "       [0.   ],\n",
       "       [0.   ],\n",
       "       [0.   ],\n",
       "       [0.   ],\n",
       "       [0.   ],\n",
       "       [0.071],\n",
       "       [0.671],\n",
       "       [0.859],\n",
       "       [0.992],\n",
       "       [0.992],\n",
       "       [0.992],\n",
       "       [0.992],\n",
       "       [0.765],\n",
       "       [0.314],\n",
       "       [0.035],\n",
       "       [0.   ],\n",
       "       [0.   ],\n",
       "       [0.   ],\n",
       "       [0.   ],\n",
       "       [0.   ],\n",
       "       [0.   ],\n",
       "       [0.   ],\n",
       "       [0.   ],\n",
       "       [0.   ],\n",
       "       [0.   ],\n",
       "       [0.   ],\n",
       "       [0.   ],\n",
       "       [0.   ],\n",
       "       [0.   ],\n",
       "       [0.   ],\n",
       "       [0.   ],\n",
       "       [0.216],\n",
       "       [0.675],\n",
       "       [0.886],\n",
       "       [0.992],\n",
       "       [0.992],\n",
       "       [0.992],\n",
       "       [0.992],\n",
       "       [0.957],\n",
       "       [0.522],\n",
       "       [0.043],\n",
       "       [0.   ],\n",
       "       [0.   ],\n",
       "       [0.   ],\n",
       "       [0.   ],\n",
       "       [0.   ],\n",
       "       [0.   ],\n",
       "       [0.   ],\n",
       "       [0.   ],\n",
       "       [0.   ],\n",
       "       [0.   ],\n",
       "       [0.   ],\n",
       "       [0.   ],\n",
       "       [0.   ],\n",
       "       [0.   ],\n",
       "       [0.   ],\n",
       "       [0.   ],\n",
       "       [0.   ],\n",
       "       [0.   ],\n",
       "       [0.533],\n",
       "       [0.992],\n",
       "       [0.992],\n",
       "       [0.992],\n",
       "       [0.831],\n",
       "       [0.529],\n",
       "       [0.518],\n",
       "       [0.063],\n",
       "       [0.   ],\n",
       "       [0.   ],\n",
       "       [0.   ],\n",
       "       [0.   ],\n",
       "       [0.   ],\n",
       "       [0.   ],\n",
       "       [0.   ],\n",
       "       [0.   ],\n",
       "       [0.   ],\n",
       "       [0.   ],\n",
       "       [0.   ],\n",
       "       [0.   ],\n",
       "       [0.   ],\n",
       "       [0.   ],\n",
       "       [0.   ],\n",
       "       [0.   ],\n",
       "       [0.   ],\n",
       "       [0.   ],\n",
       "       [0.   ],\n",
       "       [0.   ],\n",
       "       [0.   ],\n",
       "       [0.   ],\n",
       "       [0.   ],\n",
       "       [0.   ],\n",
       "       [0.   ],\n",
       "       [0.   ],\n",
       "       [0.   ],\n",
       "       [0.   ],\n",
       "       [0.   ],\n",
       "       [0.   ],\n",
       "       [0.   ],\n",
       "       [0.   ],\n",
       "       [0.   ],\n",
       "       [0.   ],\n",
       "       [0.   ],\n",
       "       [0.   ],\n",
       "       [0.   ],\n",
       "       [0.   ],\n",
       "       [0.   ],\n",
       "       [0.   ],\n",
       "       [0.   ],\n",
       "       [0.   ],\n",
       "       [0.   ],\n",
       "       [0.   ],\n",
       "       [0.   ],\n",
       "       [0.   ],\n",
       "       [0.   ],\n",
       "       [0.   ],\n",
       "       [0.   ],\n",
       "       [0.   ],\n",
       "       [0.   ],\n",
       "       [0.   ],\n",
       "       [0.   ],\n",
       "       [0.   ],\n",
       "       [0.   ],\n",
       "       [0.   ],\n",
       "       [0.   ],\n",
       "       [0.   ],\n",
       "       [0.   ],\n",
       "       [0.   ],\n",
       "       [0.   ],\n",
       "       [0.   ],\n",
       "       [0.   ],\n",
       "       [0.   ],\n",
       "       [0.   ],\n",
       "       [0.   ],\n",
       "       [0.   ],\n",
       "       [0.   ],\n",
       "       [0.   ],\n",
       "       [0.   ],\n",
       "       [0.   ],\n",
       "       [0.   ],\n",
       "       [0.   ],\n",
       "       [0.   ],\n",
       "       [0.   ],\n",
       "       [0.   ],\n",
       "       [0.   ],\n",
       "       [0.   ],\n",
       "       [0.   ],\n",
       "       [0.   ],\n",
       "       [0.   ],\n",
       "       [0.   ],\n",
       "       [0.   ],\n",
       "       [0.   ],\n",
       "       [0.   ],\n",
       "       [0.   ],\n",
       "       [0.   ],\n",
       "       [0.   ],\n",
       "       [0.   ],\n",
       "       [0.   ],\n",
       "       [0.   ],\n",
       "       [0.   ],\n",
       "       [0.   ],\n",
       "       [0.   ],\n",
       "       [0.   ],\n",
       "       [0.   ],\n",
       "       [0.   ],\n",
       "       [0.   ],\n",
       "       [0.   ],\n",
       "       [0.   ]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dp = train_data[0].reshape(28*28,1)\n",
    "dp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is the shape of the vector stored in the variable `dp`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(784, 1)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dp.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reshape all the data as column vectors:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_data = np.array([d.reshape(28*28,1) for d in train_data])\n",
    "validation_data = np.array([d.reshape(28*28,1) for d in validation_data])\n",
    "test_data = np.array([d.reshape(28*28,1) for d in test_data])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print the shape of our training data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 784, 1)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using our own Neural Network algorithm for classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Converting the labels in the MNIST data set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this purpose we can reuse the function `convert_label` that we defined before:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_label(x):\n",
    "    vec = np.zeros((10,1))\n",
    "    vec[x-1] = 1\n",
    "    return vec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert the label of the first data point in the training set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "convert_label(train_labels[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert all the label sets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels_new = np.array([convert_label(l) for l in train_labels])\n",
    "validation_labels_new = np.array([convert_label(l) for l in validation_labels])\n",
    "test_labels_new = np.array([convert_label(l) for l in test_labels])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print the shape of our new training labels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 10, 1)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels_new.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apart for two elements, the algorithm we will use here is identical to the algorithms we have been using so far. What differs is:\n",
    "- When initialising weights, we divide each weight by the square root of the number of activations in the previous layer. This makes weights values smaller for the layer after the input one. This is done because the input layer has 784 activations which would make weights too large.\n",
    "- We are using mini-batch training. Online training would be too slow, and batch training is not feasible since we have 50.000 data points. To learn step-by-step how we made mini batches, check the notebook named 'Appendix 01 - Mini batch'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To use mini batches, we will zip together data with labels into a set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = np.array(list(zip(train_data, train_labels_new)))\n",
    "validation_set = np.array(list(zip(validation_data, validation_labels_new)))\n",
    "testing_set = np.array(list(zip(test_data, test_labels_new)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "def evaluate_accuracy(dset, round_digits):\n",
    "    dlen = len(dset)\n",
    "    num_correct = 0;\n",
    "    for dp, y in dset:\n",
    "        a = dp\n",
    "        for W, b in zip(weights, biases):\n",
    "            a = sigmoid(np.dot(W, a) + b)\n",
    "        if (np.argmax(y)==np.argmax(a)):\n",
    "            num_correct += 1\n",
    "    return np.round(100*(num_correct / dlen),round_digits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1 | total cost: 22140.1405\n",
      "Training set prediction accuracy:   94.154%\n",
      "Validation set prediction accuracy: 94.06%\n",
      "\n",
      "epoch: 2 | total cost: 4698.5037\n",
      "Training set prediction accuracy:   95.698%\n",
      "Validation set prediction accuracy: 95.33%\n",
      "\n",
      "epoch: 3 | total cost: 3830.5501\n",
      "Training set prediction accuracy:   96.44%\n",
      "Validation set prediction accuracy: 95.75%\n",
      "\n",
      "epoch: 4 | total cost: 3261.6177\n",
      "Training set prediction accuracy:   96.538%\n",
      "Validation set prediction accuracy: 95.78%\n",
      "\n",
      "epoch: 5 | total cost: 2980.1646\n",
      "Training set prediction accuracy:   97.13%\n",
      "Validation set prediction accuracy: 96.02%\n",
      "\n",
      "epoch: 6 | total cost: 2687.584\n",
      "Training set prediction accuracy:   97.46%\n",
      "Validation set prediction accuracy: 96.24%\n",
      "\n",
      "epoch: 7 | total cost: 2472.1176\n",
      "Training set prediction accuracy:   97.636%\n",
      "Validation set prediction accuracy: 96.65%\n",
      "\n",
      "epoch: 8 | total cost: 2322.4483\n",
      "Training set prediction accuracy:   97.66%\n",
      "Validation set prediction accuracy: 96.23%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sizes = [784, 100, 10]\n",
    "\n",
    "num_epochs = 8\n",
    "step_size = 3\n",
    "biases = [np.random.randn(a,1) for a in sizes[1:]]\n",
    "weights = [np.random.randn(nout, nin)/np.sqrt(nin) for nout, nin in zip(sizes[1:], sizes[:-1])]\n",
    "d_biases = [np.zeros(b.shape) for b in biases]\n",
    "d_weights = [np.zeros(w.shape) for w in weights]\n",
    "no_layers = len(sizes)\n",
    "datalen = len(train_set)\n",
    "mini_batch_length = 10\n",
    "\n",
    "for epoch in np.arange(num_epochs):\n",
    "    TC = 0\n",
    "    np.random.shuffle(train_set)\n",
    "    mini_batches = [train_set[a:a+mini_batch_length] \n",
    "                    for a in range(0, datalen, mini_batch_length)]\n",
    "    for batch in mini_batches:\n",
    "        dd_biases = [np.zeros(b.shape) for b in biases]\n",
    "        dd_weights = [np.zeros(w.shape) for w in weights]\n",
    "        # single point (a,y)\n",
    "        for dp, y in batch:\n",
    "            a = dp\n",
    "            activations = [a]\n",
    "            weighted_sums = []\n",
    "            for W, b in zip(weights, biases):\n",
    "                z = np.dot(W, a) + b\n",
    "                weighted_sums.append(z)\n",
    "                a = sigmoid(z)\n",
    "                activations.append(a)\n",
    "            # cost\n",
    "            C = np.sum((a-y)**2)\n",
    "            TC += C\n",
    "            # backward pass\n",
    "            dC = 2*(a-y)\n",
    "            delta = dC * a * (1 - a)\n",
    "            d_biases[-1] = delta\n",
    "            d_weights[-1] = np.dot(delta, activations[-2].T)\n",
    "            for i in range(2, no_layers):\n",
    "                delta = activations[-i]*(1-activations[-i])*np.dot(weights[-i+1].T,delta)\n",
    "                d_biases[-i] = delta\n",
    "                d_weights[-i] = np.dot(delta, activations[-i-1].T)\n",
    "            dd_weights = [dw+ddw for dw, ddw in zip(d_weights, dd_weights)]\n",
    "            dd_biases = [db+ddb for db, ddb in zip(d_biases, dd_biases)]\n",
    "        blen = len(batch)\n",
    "        weights = [d-dw/blen*step_size for d, dw in zip(weights, dd_weights)]\n",
    "        biases = [d-db/blen*step_size for d, db in zip(biases, dd_biases)]\n",
    "    acc_train = evaluate_accuracy(train_set,4)\n",
    "    acc_validation = evaluate_accuracy(validation_set,4)\n",
    "    print (f'epoch: {epoch+1} | total cost: {np.round(TC,4)}')\n",
    "    print (f\"Training set prediction accuracy:   {acc_train}%\")\n",
    "    print (f\"Validation set prediction accuracy: {acc_validation}%\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing set prediction accuracy: 96.58%\n"
     ]
    }
   ],
   "source": [
    "acc_test = evaluate_accuracy(testing_set, 4)\n",
    "print (f\"Testing set prediction accuracy: {acc_test}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Tensorflow Keras for classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recreating our own model in Tensorflow Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential([\n",
    "  tf.keras.layers.Flatten(input_shape=(784,1)),\n",
    "  tf.keras.layers.Dense(100, activation='sigmoid'),\n",
    "  tf.keras.layers.Dense(10, activation='sigmoid')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/8\n",
      "50000/50000 [==============================] - 6s 113us/sample - loss: 0.0311 - accuracy: 0.8341 - val_loss: 0.0178 - val_accuracy: 0.9060\n",
      "Epoch 2/8\n",
      "50000/50000 [==============================] - 5s 92us/sample - loss: 0.0168 - accuracy: 0.9062 - val_loss: 0.0141 - val_accuracy: 0.9200\n",
      "Epoch 3/8\n",
      "50000/50000 [==============================] - 5s 94us/sample - loss: 0.0141 - accuracy: 0.9206 - val_loss: 0.0123 - val_accuracy: 0.9289\n",
      "Epoch 4/8\n",
      "50000/50000 [==============================] - 5s 95us/sample - loss: 0.0125 - accuracy: 0.9292 - val_loss: 0.0111 - val_accuracy: 0.9355\n",
      "Epoch 5/8\n",
      "50000/50000 [==============================] - 5s 95us/sample - loss: 0.0113 - accuracy: 0.9359 - val_loss: 0.0102 - val_accuracy: 0.9404\n",
      "Epoch 6/8\n",
      "50000/50000 [==============================] - 5s 95us/sample - loss: 0.0103 - accuracy: 0.9408 - val_loss: 0.0096 - val_accuracy: 0.9445\n",
      "Epoch 7/8\n",
      "50000/50000 [==============================] - 5s 94us/sample - loss: 0.0096 - accuracy: 0.9458 - val_loss: 0.0092 - val_accuracy: 0.9469\n",
      "Epoch 8/8\n",
      "50000/50000 [==============================] - 5s 95us/sample - loss: 0.0089 - accuracy: 0.9491 - val_loss: 0.0085 - val_accuracy: 0.9522\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer=tf.keras.optimizers.SGD(learning_rate = 3.0),\n",
    "              loss='mse',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(train_data, \n",
    "                    train_labels_new, \n",
    "                    validation_data=(validation_data,validation_labels_new), \n",
    "                    epochs=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/1 - 0s - loss: 0.0044 - accuracy: 0.9558\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.00819785578874871, 0.9558]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(test_data, test_labels_new, verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using the recommended Tensorflow Keras parameters "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential([\n",
    "  tf.keras.layers.Flatten(input_shape=(784,1)),\n",
    "  tf.keras.layers.Dense(128, activation='relu'),\n",
    "  tf.keras.layers.Dropout(0.2),\n",
    "  tf.keras.layers.Dense(10)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/8\n",
      "50000/50000 [==============================] - 7s 143us/sample - loss: 0.3222 - accuracy: 0.9077 - val_loss: 0.1518 - val_accuracy: 0.9552\n",
      "Epoch 2/8\n",
      "50000/50000 [==============================] - 6s 129us/sample - loss: 0.1587 - accuracy: 0.9523 - val_loss: 0.1080 - val_accuracy: 0.9677\n",
      "Epoch 3/8\n",
      "50000/50000 [==============================] - 6s 126us/sample - loss: 0.1201 - accuracy: 0.9641 - val_loss: 0.0907 - val_accuracy: 0.9726\n",
      "Epoch 4/8\n",
      "50000/50000 [==============================] - 6s 128us/sample - loss: 0.0948 - accuracy: 0.9709 - val_loss: 0.0810 - val_accuracy: 0.9744\n",
      "Epoch 5/8\n",
      "50000/50000 [==============================] - 7s 131us/sample - loss: 0.0812 - accuracy: 0.9746 - val_loss: 0.0779 - val_accuracy: 0.9750\n",
      "Epoch 6/8\n",
      "50000/50000 [==============================] - 7s 135us/sample - loss: 0.0708 - accuracy: 0.9776 - val_loss: 0.0783 - val_accuracy: 0.9760\n",
      "Epoch 7/8\n",
      "50000/50000 [==============================] - 7s 134us/sample - loss: 0.0638 - accuracy: 0.9792 - val_loss: 0.0906 - val_accuracy: 0.9741\n",
      "Epoch 8/8\n",
      "50000/50000 [==============================] - 7s 130us/sample - loss: 0.0563 - accuracy: 0.9820 - val_loss: 0.0773 - val_accuracy: 0.9770\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer=tf.keras.optimizers.Adam(),\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(train_data, \n",
    "                    train_labels, \n",
    "                    validation_data=(validation_data, validation_labels),\n",
    "                    epochs=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/1 - 0s - loss: 0.0398 - accuracy: 0.9772\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.07854250898621977, 0.9772]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(test_data, test_labels, verbose=2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
